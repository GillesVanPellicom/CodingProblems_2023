# [Evaluate mathematical expression](https://www.codewars.com/kata/52a78825cdfc2cfc87000005/java)
###### Site Difficulty: 2 kyu / Perceived difficulty: Hard
Given a mathematical expression as a string you must return the result as a number.
### Numbers
Number may be both whole numbers and/or decimal numbers. The same goes for the returned result.

### Operators
You need to support the following mathematical operators:

- Multiplication ```*```
- Division ```/``` (as floating point division)
- Addition ```+```
- Subtraction ```-```
- Operators are always evaluated from left-to-right, and ```*``` and ```/``` must be evaluated before ```+``` and ```-```.

### Parentheses
You need to support multiple levels of nested parentheses, ex. ```(2 / (2 + 3.33) * 4) - -6```

### Whitespace
There may or may not be whitespace between numbers and operators.

An addition to this rule is that the minus sign (```-```) used for negating numbers and parentheses will never be separated by whitespace. I.e all of the following are valid expressions.
```
1-1    // 0
1 -1   // 0
1- 1   // 0
1 - 1  // 0
1- -1  // 2
1 - -1 // 2
1--1   // 2

6 + -(4)   // 2
6 + -( -4) // 10
```
And the following are **invalid** expressions
```
1 - - 1    // Invalid
1- - 1     // Invalid
6 + - (4)  // Invalid
6 + -(- 4) // Invalid
```
### Validation
You do not need to worry about validation - you will only receive **valid** mathematical expressions following the above rules.

### Restricted APIs
**NOTE**: To keep up the difficulty of the kata, use of some classes and functions is disallowed. Their names cannot appear in the solution file, even in comments and variable names.
## Personal notes:
This at first sight deceptively simple problem had me thinking for a bit. The bracket depth is the biggest obstacle to overcome. I thought about simply using a stack of some sorts to keep track of the brackets, but this would only work if I wanted to know if all brackets are closed. I could probably pour the expression into a tree and then use some implementation of [DFS](https://en.wikipedia.org/wiki/Depth-first_search), but I like to avoid tree structures whenever possible since they are unwieldy to work with.

I remembered [POSTFIX](https://en.wikipedia.org/wiki/Reverse_Polish_notation) notation could be used by a computer to easily evaluate an expression since brackets don't exist in POSTFIX.

So my plan was to write a tokenizer ( ```"a+b" -> [a, +, b]```), pipe that into an [INFIX](https://en.wikipedia.org/wiki/Infix_notation) to POSTFIX algorithm (```[a, +, b] -> [a, b, +]```) and pipe that to a standard POSTFIX evaluation algorithm to get my result.

I could make the tokenizer using regex and the evaluator is just a for loop and a stack. The only unknown was the notation converter. After some reading I came across [Dijkstra's Shunting Yard algorithm](https://en.wikipedia.org/wiki/Shunting_yard_algorithm). After messing arround with the implementation for a while I got it to work and converted my INFIX tokens generated by the tokenizer to POSTFIX.
The issue was that this only works when the input expression exclusively contains binary operators. E.g. ```a + b```. 
In POSTFIX this would be ```a b +```. Now what if we introduce a unary operator such as in this example: ```-1```? The algorithm breaks down when we do this. It won't complain or throw any errors, but now the output will just be completely useless.

My first instinct was to minimize any inputs before it gets to the tokenizer. E.g. ```4 + (-3)``` becomes ```4 - 3```. After some trial and error I managed to get, I'd like to say, 20% success rates. The reason this is concidered a non-trivial issue in the first place is because it's hard to work with INFIX notation. Needless to say I promptly scrapped that idea.

After more time than I'd like to admit I figured out I could just check in the tokenizer if the minus operator succeeds another operator. If it does then it's a unary operator and I could just give it a different character as token to distinguish itself from the binary minus operator.

When trying to implement this I came to the conclusion that my code was not at all clean or modular enough to continue working on and that it was better to scrap some functions and start over with my freshly acquired knowledge.

The two biggest changes were the change over from a simple tokenizer to a [lexer](https://en.wikipedia.org/wiki/Lexical_analysis) that divides my string into lexemes, making it much easier to work with, and the use of enumerations for type safety. These two changes made it easier to modify and read the code.

After some debugging and unforeseen interactions my code passed all unit tests. 

Time complexity: $O(n)$
